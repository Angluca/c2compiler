/* Copyright 2022-2025 Bas van den Berg
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

module ir_generator;

import ast;
import ctv_analyser;

import stdlib;
import string;

type FieldInit struct {
    u32 offset;
    u32 is_bitfield : 1;
    u32 bit_offset : 6;
    u32 bit_width : 7;
    ast.Expr* expr;
}
static_assert(16, sizeof(FieldInit));

type FieldStructLayouter struct {
    Generator* gen;
    u32 size;

    FieldInit* inits;
    u32 num_inits;
    u32 max_inits;
}

fn void FieldStructLayouter.init(FieldStructLayouter* l,
                                     Generator* gen,
                                     u32 struct_size,
                                     u32 num_members) {
    l.gen = gen;
    l.size = struct_size;
    l.num_inits = 0;
    l.inits = nil;
    l.resize(num_members);
}

fn void FieldStructLayouter.resize(FieldStructLayouter* l, u32 max) {
    l.max_inits = max;
    FieldInit* inits = stdlib.malloc(max * sizeof(FieldInit));
    if (l.num_inits) string.memcpy(inits, l.inits, l.num_inits * sizeof(FieldInit));
    if (l.inits) stdlib.free(l.inits);
    l.inits = inits;
}

fn void FieldStructLayouter.add(FieldStructLayouter* l,
                                u32 offset,
                                bool is_bitfield,
                                u8 bit_offset,
                                u8 bit_width,
                                ast.Expr* value) {
    if (l.num_inits == l.max_inits) l.resize(l.max_inits * 2);


#if 0
    // UNTIL fixed in bootstrap
    FieldInit init = { .offset=offset,
                       .is_bitfield=is_bitfield,
                       .bit_offset = bit_offset,
                       .bit_width = bit_width,
                       .expr=value };
#else
    FieldInit init;
    init.offset=offset;
    init.is_bitfield=is_bitfield;
    init.bit_offset = bit_offset;
    init.bit_width = bit_width;
    init.expr=value;
#endif
    if (l.num_inits == 0) {
        l.inits[0] = init;
        l.num_inits = 1;
        return;
    }

    // insert sorted
    u32 idx = l.num_inits;
    while (idx) {
        FieldInit* fi = &l.inits[idx-1];
        if (offset > fi.offset) break;
        l.inits[idx] = *fi; // move up
        idx--;
    }
    l.inits[idx] = init;
    l.num_inits++;
}

fn void FieldStructLayouter.finalize(FieldStructLayouter* l) {
    u32 cur_offset = 0;
    bool have_bitfield = false;
    u8 bitfield_size = 0;   // in bytes of whole field
    u64 bitfield_value = 0; // will be downsized to correct size later

    for (u32 i=0; i<l.num_inits; i++) {
        const FieldInit* fi = &l.inits[i];
        const ast.Expr* e = fi.expr;
        ast.QualType qt = e.getType();
        u32 size = qt.getSize(false);

        u32 pad = fi.offset - cur_offset;
        if (pad) {
            //printf("FIELD offset %d -> %d\n", cur_offset, fi.offset);
            if (have_bitfield) {
                //printf("  outstanding bitfield\n");
                l.gen.emitBitfield(bitfield_size, bitfield_value);
                cur_offset += bitfield_size;
                pad -= bitfield_size;
                have_bitfield = false;
                bitfield_value = 0;
                bitfield_size = 0;
                if (!pad) goto field;
            }
            assert(fi.offset > cur_offset);
            //printf("PAD1 %d\n", pad);
            l.gen.ctx.addInitZero(pad);
            cur_offset = fi.offset;
        }
field:

        if (fi.is_bitfield) {
            have_bitfield = true;
            bitfield_size = (u8)size;

            //printf("BITFIELD(%d, %d) size %d\n", fi.bit_offset, fi.bit_width, bitfield_size);

            if (e.isCtv()) {
                ast.Value value = ctv_analyser.get_value(e);
                value.mask(fi.bit_width);
                value.left_shift2(fi.bit_offset);
                u64 v = value.as_u64();
                bitfield_value |= v;
                //printf("  Value 0x%x  => %x\n", v, bitfield_value);
            } else {
                assert(0);  // TODO
            }
        } else {
            l.gen.emitInit(e, size);
            cur_offset = fi.offset + size;
        }
    }

    if (have_bitfield) {
        //printf("END flush bitfield (%d)\n", bitfield_size);
        l.gen.emitBitfield(bitfield_size, bitfield_value);
        cur_offset += bitfield_size;
    }

    // emit final padding
    if (cur_offset != l.size) {
        assert(l.size > cur_offset);
        u32 pad = l.size - cur_offset;
        //printf("PAD2 %d (size %d off %d)\n", pad, l.size, cur_offset);
        l.gen.ctx.addInitZero(pad);
    }

    stdlib.free(l.inits);
}

